{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014285714285714285,
      "grad_norm": 0.22374030947685242,
      "learning_rate": 9.433962264150944e-05,
      "loss": 4.0207,
      "step": 25
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 0.4831840693950653,
      "learning_rate": 0.00018867924528301889,
      "loss": 5.2678,
      "step": 50
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 0.47675544023513794,
      "learning_rate": 0.00019991707387086134,
      "loss": 3.3648,
      "step": 75
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 0.9174173474311829,
      "learning_rate": 0.00019962170746297674,
      "loss": 3.7447,
      "step": 100
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 0.7559001445770264,
      "learning_rate": 0.00019911299110932996,
      "loss": 2.6655,
      "step": 125
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 0.8560734391212463,
      "learning_rate": 0.00019839201427735947,
      "loss": 2.478,
      "step": 150
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7384971976280212,
      "learning_rate": 0.00019746032101175117,
      "loss": 2.2215,
      "step": 175
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.7456067204475403,
      "learning_rate": 0.0001963199066277103,
      "loss": 2.2331,
      "step": 200
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 0.6637065410614014,
      "learning_rate": 0.00019497321343779292,
      "loss": 2.0227,
      "step": 225
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 1.0249590873718262,
      "learning_rate": 0.00019342312552144656,
      "loss": 2.1753,
      "step": 250
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 0.6540383100509644,
      "learning_rate": 0.00019167296254846304,
      "loss": 1.9577,
      "step": 275
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 0.6986164450645447,
      "learning_rate": 0.00018972647266957056,
      "loss": 2.0152,
      "step": 300
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 0.7253809571266174,
      "learning_rate": 0.00018758782448939014,
      "loss": 1.8757,
      "step": 325
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7754111289978027,
      "learning_rate": 0.00018526159813894805,
      "loss": 1.971,
      "step": 350
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 0.7909363508224487,
      "learning_rate": 0.00018275277546686284,
      "loss": 1.7872,
      "step": 375
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.6296688914299011,
      "learning_rate": 0.00018006672937021336,
      "loss": 2.0357,
      "step": 400
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 0.6699853539466858,
      "learning_rate": 0.0001772092122879371,
      "loss": 1.751,
      "step": 425
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 0.6629898548126221,
      "learning_rate": 0.00017418634388140155,
      "loss": 1.9842,
      "step": 450
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 0.7846428751945496,
      "learning_rate": 0.00017100459792853125,
      "loss": 1.8801,
      "step": 475
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.7505471110343933,
      "learning_rate": 0.00016767078845955876,
      "loss": 1.931,
      "step": 500
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0555543899536133,
      "learning_rate": 0.00016419205516409092,
      "loss": 1.7414,
      "step": 525
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 0.9295557141304016,
      "learning_rate": 0.0001605758481007426,
      "loss": 1.8305,
      "step": 550
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 0.6735183000564575,
      "learning_rate": 0.00015682991174208378,
      "loss": 1.6446,
      "step": 575
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.7256276607513428,
      "learning_rate": 0.00015296226838906982,
      "loss": 1.8074,
      "step": 600
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.8286963701248169,
      "learning_rate": 0.0001489812009904737,
      "loss": 1.7662,
      "step": 625
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 0.7824448943138123,
      "learning_rate": 0.0001448952354041149,
      "loss": 1.8301,
      "step": 650
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 0.9996713399887085,
      "learning_rate": 0.0001407131221378741,
      "loss": 1.6009,
      "step": 675
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7643595337867737,
      "learning_rate": 0.00013644381760959681,
      "loss": 1.8855,
      "step": 700
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 0.6715048551559448,
      "learning_rate": 0.0001320964649660203,
      "loss": 1.6886,
      "step": 725
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.7090941071510315,
      "learning_rate": 0.00012768037450180156,
      "loss": 1.8359,
      "step": 750
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 0.8043550848960876,
      "learning_rate": 0.0001232050037205813,
      "loss": 1.6643,
      "step": 775
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.7527002096176147,
      "learning_rate": 0.00011867993708078484,
      "loss": 1.7634,
      "step": 800
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 0.5631463527679443,
      "learning_rate": 0.00011411486546953671,
      "loss": 1.6684,
      "step": 825
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 0.6771289110183716,
      "learning_rate": 0.00010951956544864714,
      "loss": 1.8036,
      "step": 850
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.55216383934021,
      "learning_rate": 0.00010490387831711799,
      "loss": 1.6047,
      "step": 875
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 0.6991512775421143,
      "learning_rate": 0.00010027768903500721,
      "loss": 1.7913,
      "step": 900
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 0.7425747513771057,
      "learning_rate": 9.565090505378846e-05,
      "loss": 1.5157,
      "step": 925
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 0.5634466409683228,
      "learning_rate": 9.103343509854379e-05,
      "loss": 1.8162,
      "step": 950
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 0.6990063190460205,
      "learning_rate": 8.643516794742801e-05,
      "loss": 1.4535,
      "step": 975
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.5855689644813538,
      "learning_rate": 8.186595125385198e-05,
      "loss": 1.8203,
      "step": 1000
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 0.6581661105155945,
      "learning_rate": 7.733557045673834e-05,
      "loss": 1.5667,
      "step": 1025
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.66665118932724,
      "learning_rate": 7.285372782401609e-05,
      "loss": 1.781,
      "step": 1050
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 0.7633824348449707,
      "learning_rate": 6.843002167423403e-05,
      "loss": 1.5015,
      "step": 1075
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.8495567440986633,
      "learning_rate": 6.407392582079247e-05,
      "loss": 1.7262,
      "step": 1100
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 0.7657716870307922,
      "learning_rate": 5.97947692828152e-05,
      "loss": 1.5094,
      "step": 1125
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 0.6413022875785828,
      "learning_rate": 5.560171630611303e-05,
      "loss": 1.7443,
      "step": 1150
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 0.775474488735199,
      "learning_rate": 5.150374673702607e-05,
      "loss": 1.5792,
      "step": 1175
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 1.075724720954895,
      "learning_rate": 4.7509636791176114e-05,
      "loss": 1.6926,
      "step": 1200
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.619439423084259,
      "learning_rate": 4.36279402583145e-05,
      "loss": 1.5588,
      "step": 1225
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.6610722541809082,
      "learning_rate": 3.9866970183517915e-05,
      "loss": 1.6515,
      "step": 1250
    },
    {
      "epoch": 0.7285714285714285,
      "grad_norm": 0.672667384147644,
      "learning_rate": 3.623478106396281e-05,
      "loss": 1.5109,
      "step": 1275
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.7322072982788086,
      "learning_rate": 3.273915159940636e-05,
      "loss": 1.7703,
      "step": 1300
    },
    {
      "epoch": 0.7571428571428571,
      "grad_norm": 0.7369043231010437,
      "learning_rate": 2.938756803331556e-05,
      "loss": 1.5381,
      "step": 1325
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 0.5890224575996399,
      "learning_rate": 2.6187208120320994e-05,
      "loss": 1.7001,
      "step": 1350
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 0.7262037992477417,
      "learning_rate": 2.3144925754330315e-05,
      "loss": 1.5607,
      "step": 1375
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6498270630836487,
      "learning_rate": 2.0267236290222602e-05,
      "loss": 1.7063,
      "step": 1400
    },
    {
      "epoch": 0.8142857142857143,
      "grad_norm": 0.6575759053230286,
      "learning_rate": 1.7560302590557897e-05,
      "loss": 1.5465,
      "step": 1425
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 0.6327821612358093,
      "learning_rate": 1.5029921827184657e-05,
      "loss": 1.7477,
      "step": 1450
    },
    {
      "epoch": 0.8428571428571429,
      "grad_norm": 0.7579715847969055,
      "learning_rate": 1.2681513066011052e-05,
      "loss": 1.5137,
      "step": 1475
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.5863778591156006,
      "learning_rate": 1.0520105661528068e-05,
      "loss": 1.6937,
      "step": 1500
    },
    {
      "epoch": 0.8714285714285714,
      "grad_norm": 0.69269198179245,
      "learning_rate": 8.550328485938885e-06,
      "loss": 1.5631,
      "step": 1525
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 0.9105098247528076,
      "learning_rate": 6.776400015961881e-06,
      "loss": 1.6313,
      "step": 1550
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7381285429000854,
      "learning_rate": 5.2021192985367004e-06,
      "loss": 1.507,
      "step": 1575
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.5619350671768188,
      "learning_rate": 3.83085781478153e-06,
      "loss": 1.6852,
      "step": 1600
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 0.6332618594169617,
      "learning_rate": 2.6655522596259917e-06,
      "loss": 1.4822,
      "step": 1625
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 0.7520769834518433,
      "learning_rate": 1.7086982525823636e-06,
      "loss": 1.6795,
      "step": 1650
    },
    {
      "epoch": 0.9571428571428572,
      "grad_norm": 0.670472264289856,
      "learning_rate": 9.623449931243422e-07,
      "loss": 1.5019,
      "step": 1675
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.5461862683296204,
      "learning_rate": 4.280908721195465e-07,
      "loss": 1.6006,
      "step": 1700
    },
    {
      "epoch": 0.9857142857142858,
      "grad_norm": 0.6651113629341125,
      "learning_rate": 1.0708004871404775e-07,
      "loss": 1.4839,
      "step": 1725
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.576436460018158,
      "learning_rate": 0.0,
      "loss": 1.7142,
      "step": 1750
    }
  ],
  "logging_steps": 25,
  "max_steps": 1750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 235513591160832.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
